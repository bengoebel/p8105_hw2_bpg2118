---
title: "p8105_hw2_bpg2118"
author: "Benjamin Goebel"
date: "10/9/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)
```

#### **Problem 1**  
Let's do the following:

*   Read in the excel file for the Mr. Trash Wheel data set. 
*   Clean the variables names. 
*   Remove any rows that do not have a dumpster number.
*   Remove any empty columns that R reads in as "x#".
*   Round the number of sports balls to the nearest integer.

```{r message=FALSE}
# Read and Clean the Mr. Trash Wheel Data
mr_trash_wheel <- 
  readxl::read_xlsx(path = here("hw2_data",
                                "Trash-Wheel-Collection-Totals-8-6-19.xlsx"),
                    sheet = "Mr. Trash Wheel") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  select(-starts_with("x")) %>%
  mutate(sports_balls = round(sports_balls, digits = 0))
```

A few points about this data set:  

*   There are `r nrow(mr_trash_wheel)` rows (one row for each dumpster
collected) in the data set and 
there are `r ncol(mr_trash_wheel)` columns.
*   The mean number of plastic bottles per dumpster is 
`r round(mean(pull(mr_trash_wheel, plastic_bottles)), 2)`.
*   The median number of glass bottles is 
`r median(pull(mr_trash_wheel, glass_bottles))`.
*   The maximum weight of a single dumpster is 
`r max(pull(mr_trash_wheel, weight_tons))` tons.
*   The minimum weight of a single dumpster is
`r min(pull(mr_trash_wheel, weight_tons))` tons.
*   The median number of sports balls in a dumpster in 2019 was
`r median(pull(filter(mr_trash_wheel, year == 2019), sports_balls))`.

Next, let's do the following:

*   Read in the precipitation data for 2018 and 2019.  
*   Clean variable names.
*   Filter any row without precipitation data.  

Additionally, when reading in this data, we can skip the first row, as it does 
not contain column names nor actual data.
```{r}
# Read and Clean the 2018 and 2019 Precipitation Data
# Skip first row, which does not contain data
eighteen_precip <- 
  readxl::read_xlsx(path = here("hw2_data",
                                "Trash-Wheel-Collection-Totals-8-6-19.xlsx"),
                    sheet = "2018 Precipitation",
                    skip = 1) %>%
  janitor::clean_names() %>%
  filter(!is.na(month), !is.na(total))
nineteen_precip <- 
  readxl::read_xlsx(path = here("hw2_data",
                                "Trash-Wheel-Collection-Totals-8-6-19.xlsx"),
                    sheet = "2019 Precipitation",
                    skip = 1) %>%
  janitor::clean_names() %>%
  filter(!is.na(month), !is.na(total))
```

Further, because precipitation is measured in inches, we 
can indicate this unit in the total variable name.

```{r}
eighteen_precip <- rename(eighteen_precip, total_precip_inches = total)
nineteen_precip <- rename(nineteen_precip, total_precip_inches = total)
```

Next, let's add a year variable and make it the leftmost column for the 2018 
and 2019 precipitation data frames.
```{r}
# Add year variable and position as the leftmost column
eighteen_precip <- eighteen_precip %>%
  mutate(year = 2018) %>%
  relocate(year)

nineteen_precip <- nineteen_precip %>%
  mutate(year = 2019) %>%
  relocate(year)
```

Now, we can combine the precipitation data sets and convert the month variable
to a character variable.
```{r}
eighteen_nineteen_precip <- bind_rows(eighteen_precip, nineteen_precip) %>%
  mutate(month = month.name[month])
```

Finally, here are some facts about the precipitation data:  

*   There are `r nrow(eighteen_precip)` rows (one row for each month) and 
`r ncol(eighteen_precip)` columns in the 2018 precipitation data.
*   There are `r nrow(nineteen_precip)` rows and 
`r ncol(nineteen_precip)` columns in the 2019 precipitation data.
    * Notice that we are missing data for the 2019 precipitation data.
*   The total precipitation in 2018 was 
`r sum(pull(eighteen_precip, total_precip_inches))` inches, and 
the total precipitation in 2019, for the data we have, was 
`r sum(pull(nineteen_precip, total_precip_inches))` inches.
*   The month with the minimum precipitation in 2018 was
`r first(pull(arrange(filter(eighteen_nineteen_precip, year == 2018), 
              total_precip_inches), month))`, and the month with the maximum
precipitation in 2018 was
`r first(pull(arrange(filter(eighteen_nineteen_precip, year == 2018), 
              desc(total_precip_inches)), month))`.
*   The month with the minimum precipitation in 2019 was
`r first(pull(arrange(filter(eighteen_nineteen_precip, year == 2019), 
              total_precip_inches), month))`, and the month with the maximum
precipitation in 2019 was
`r first(pull(arrange(filter(eighteen_nineteen_precip, year == 2019), 
              desc(total_precip_inches)), month))` for the data we have.

#### **Problem 2**  
First, let's do the following for the pols-month data:  

*   Read in the pols-month data.
*   Separate the mon variable into year, month and day variables.
*   Replace the month number with the month name.
*   Create a president variable, indicating the president's 
political affiliation (gop or dem).
*   Remove prez_dem, prez_gop and the day variables.
```{r message=FALSE}
# Read and clean the pols-month data
pols_month <- read_csv(here("hw2_data",
                            "fivethirtyeight_datasets",
                            "pols-month.csv")) %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = month.name[as.integer(month)],
         president = ifelse(as.logical(prez_dem), "dem", "gop")) %>%
  select(-prez_dem, -prez_gop, -day)
```
The pols-month data contains data on politicians and their respective
political affiliations at the state and federal level. The data set has 
`r nrow(pols_month)` rows and `r ncol(pols_month)` columns. It contains 
political data from `r min(pull(pols_month, year))` to 
`r max(pull(pols_month, year))`. There is one row observation for every
month in this time frame. The key variables indicate the number of
Republicans and Democrats who are governors, representatives and senators. 
The data set also has a key variable for the political 
affiliation of the president. In the time frame of this data set, 
there has been a Republican president for 
`r nrow(filter(pols_month, president == "gop"))` months, and
there has been a Democrat president for 
`r nrow(filter(pols_month, president == "dem"))` months.

Second, let's do the following for the snp data:

*   Read in the snp data.
*   Separate the date variable into year, month and day variables.
*   Replace the month number with a month name.
*   Remove the day variable.  

```{r message=FALSE}
# Read and clean the snp data. The years are two digits (YY). Used lubridate
# to create dates with 4 digit years (YYYY). I then separated the different date
# components. Subtracted the year by 100 if lubridate 
# incorrectly parsed a year as being from the 2000s if it was actually 
# from the 1900s.
snp <- read_csv(here("hw2_data",
                     "fivethirtyeight_datasets",
                     "snp.csv")) %>%
  mutate(date = lubridate::mdy(date)) %>%
  separate(date, into = c("year", "month", "day"), sep = "-") %>%
  mutate(year = as.integer(year)) %>%
  mutate(year = as.character(ifelse(year > 2021, year - 100, year)),
         month = month.name[as.integer(month)]) %>%
  select(-day)
```
The snp data contains closing price data of the S&P index over time. There
are `r nrow(snp)` rows and `r ncol(snp)` columns. Data is collected from
`r min(pull(snp, year))` to `r max(pull(snp, year))`. Similar to the
pols-month data, there is one row observation for every month in this
time frame. Additionally, this time span is similar to that of the pols-month 
data except that data collection started three years
later for the snp data than it did for the pols-month data. The key variable
in this data set is close, which is the closing price of the S&P index on the
observed date. The median closing price of the S&P index in the data set is
$`r round(median(pull(snp, close)), 2)`.

Third, let's do the following for the unemployment data:

*   Read in the unemployment data.
*   Pivot the month data from wide to long format (bring all the month columns
into one column).
*   Convert the month from three character abbreviation to full month name.
*   Make the year column name all lowercase.
*   Convert year from a double to a character.
*   Remove any rows that do not contain an unemployment percent.

```{r message =FALSE}
# Read and clean the unemployment data. The months are encoded as
# abbreviations. To convert to full month names, convert month abbreviations to
# month numbers. Then, convert month numbers to full month names.
unemployment <- read_csv(here("hw2_data",
                              "fivethirtyeight_datasets",
                              "unemployment.csv")) %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment_pct"
  ) %>%
  mutate(month = month.name[match(month, month.abb)]) %>%
  rename(year = Year) %>%
  mutate(year = as.character(year)) %>%
  filter(!is.na(unemployment_pct))
```
The unemployment data contains unemployment percentages over time. There
are `r nrow(unemployment)` rows and `r ncol(unemployment)` columns. Data is 
collected from `r min(pull(unemployment, year))` to 
`r max(pull(unemployment, year))`. Similar to the pols-month data, there is one 
row observation for every month in this time frame. Additionally, this time 
span is similar to that of the pols-month data except that data collection 
started one year later for the unemployment data than it did for the 
pols-month data. The key variable in this data set is 
unemployment_pct, which is the unemployment percentage on 
the observed date. The median unemployment
percentage is 
`r round(median(pull(unemployment, unemployment_pct)), 2)`%.

Fourth, let's join the data together.
```{r}
# Join the data together
pols_snp_unemployment <- 
left_join(left_join(pols_month, snp, by = c("year", "month")),
          unemployment, by = c("year", "month"))
```

This data set has `r nrow(pols_snp_unemployment)` rows and
`r ncol(pols_snp_unemployment)` columns. When a Republican has
been president, the average S&P closing price has been 
$`r round(mean(pull(filter(pols_snp_unemployment, president == "gop"), close),
na.rm = TRUE), 2)` and the average unemployment percentage has been
`r round(mean(pull(filter(pols_snp_unemployment, president == "gop"), 
              unemployment_pct), na.rm = TRUE), 2)`%. When a Democrat has
been president, the average S&P closing price has been
$`r round(mean(pull(filter(pols_snp_unemployment, president == "dem"), close),
                 na.rm = TRUE), 2)` and the average unemployment percentage has
been `r round(mean(pull(filter(pols_snp_unemployment, president == "dem"),
                        unemployment_pct), na.rm = TRUE), 2)`%.

#### **Problem 3**
First, let's do the following to the popular baby names data:

*   Read in the popular baby names data.
*   Clean the column names.
*   Recode the ethnicity variable to account for same values that
are coded differently.
*   Convert the childs_first_name variable to title case to account for the
same names with different capitalizations.
*   Remove duplicate rows.

```{r message=FALSE}
# Read and clean the popular baby names data
popular_baby_names <- 
  read_csv(here("hw2_data", "Popular_Baby_Names.csv")) %>%
  janitor::clean_names() %>%
  mutate(ethnicity = recode(ethnicity,
                            "ASIAN AND PACI" = "ASIAN AND PACIFIC ISLANDER",
                            "BLACK NON HISP" = "BLACK NON HISPANIC",
                            "WHITE NON HISP" = "WHITE NON HISPANIC"),
         childs_first_name = str_to_title(childs_first_name)) %>%
  distinct()

```
With our cleaned data, we can proceed. We will now produce a table to
show the popularity of the name "Olivia" over the years. Each year will be a
column and each ethnicity will be a row. For this table, all rows have a gender 
value equal to "FEMALE", so we will not include this column. We will also not
include the rank column as it is not relevant here.

```{r}
# Filter rows.
# Pivot wide year column.
# Select columns.
# Output table.
popular_baby_names %>%
  filter(childs_first_name == "Olivia") %>%
  select(year_of_birth, ethnicity, childs_first_name, count) %>%
  pivot_wider(names_from = "year_of_birth",
              values_from = "count") %>%
  select(childs_first_name, ethnicity, `2011`:`2016`) %>%
  knitr::kable(caption = "Popularity of the name Olivia from 2011 to 2016 
                          stratified by ethnicity.")
```

Next, we will produce a table showing the most popular name among male children
over time. It will have the same columns as the previous table did.

```{r}
# Filter rows and columns.
# Pivot wide year column.
# Select columns.
# Output table.
popular_baby_names %>%
  filter(gender == "MALE", rank == 1) %>%
  select(year_of_birth, ethnicity, childs_first_name) %>%
  pivot_wider(names_from = "year_of_birth",
              values_from = "childs_first_name") %>%
  select(ethnicity, `2011`:`2016`) %>%
  knitr::kable(caption = "Most popular names among male children from 2011 
                          to 2016.")
```

Finally, for male, white non-hispanic children born in 2016, we will produce a 
scatter plot visualizing the number of children with a given name (y axis) 
against the rank in popularity of that name (x axis).

```{r}
# Filter to desired population.
# Create plot.
# Label axes and title.
# Center title.
popular_baby_names %>%
  filter(gender == "MALE", ethnicity == "WHITE NON HISPANIC", 
         year_of_birth == 2016) %>%
  ggplot(aes(x = rank, y = count)) +
    geom_point() +
  labs(
    title = "Name Count as a Function of Name Rank among Male, White 
             Non-Hispanic Children Born in 2016",
    y = "Name Count",
    x = "Name Rank"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```


